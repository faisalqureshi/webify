{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 10 # number of data points\n",
    "m = .7\n",
    "c = 0\n",
    "x = np.linspace(0,2*np.pi,N)\n",
    "y = m*x + c + np.random.normal(0,.3,x.shape)\n",
    "plt.figure()\n",
    "plt.plot(x,y,'o')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('2D data (#data = %d)' % N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'feature': torch.tensor([1,self.x[idx]]), \n",
    "            'label': torch.tensor([self.y[idx]])}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([1., 0.]) tensor([-0.0810])\n",
      "1 tensor([1.0000, 0.6981]) tensor([0.3358])\n",
      "2 tensor([1.0000, 1.3963]) tensor([1.1995])\n",
      "3 tensor([1.0000, 2.0944]) tensor([1.6029])\n",
      "4 tensor([1.0000, 2.7925]) tensor([1.0966])\n",
      "5 tensor([1.0000, 3.4907]) tensor([2.1744])\n",
      "6 tensor([1.0000, 4.1888]) tensor([2.8280])\n",
      "7 tensor([1.0000, 4.8869]) tensor([3.2023])\n",
      "8 tensor([1.0000, 5.5851]) tensor([3.6039])\n",
      "9 tensor([1.0000, 6.2832]) tensor([4.8596])\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(x, y)\n",
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "    print(i, sample['feature'], sample['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = MyDataset(x, y)\n",
    "batch_size = 4\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch# = 0\n",
      "samples: \n",
      "{'feature': tensor([[1.0000, 6.2832],\n",
      "        [1.0000, 3.4907],\n",
      "        [1.0000, 2.7925],\n",
      "        [1.0000, 1.3963]]),\n",
      " 'label': tensor([[4.8596],\n",
      "        [2.1744],\n",
      "        [1.0966],\n",
      "        [1.1995]])}\n",
      "\n",
      "batch# = 1\n",
      "samples: \n",
      "{'feature': tensor([[1.0000, 5.5851],\n",
      "        [1.0000, 4.8869],\n",
      "        [1.0000, 4.1888],\n",
      "        [1.0000, 2.0944]]),\n",
      " 'label': tensor([[3.6039],\n",
      "        [3.2023],\n",
      "        [2.8280],\n",
      "        [1.6029]])}\n",
      "\n",
      "batch# = 2\n",
      "samples: \n",
      "{'feature': tensor([[1.0000, 0.0000],\n",
      "        [1.0000, 0.6981]]),\n",
      " 'label': tensor([[-0.0810],\n",
      "        [ 0.3358]])}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "for i_batch, samples in enumerate(dataloader):\n",
    "    print('\\nbatch# = %s' % i_batch)\n",
    "    print('samples: ')\n",
    "    pp.pprint(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.weight = Parameter(torch.Tensor(output_dim, input_dim))\n",
    "        self.bias = Parameter(torch.Tensor(output_dim, 1))\n",
    "        \n",
    "        stdv = 1.\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        weight_and_bias = torch.cat((self.weight, self.bias), 1)\n",
    "        #print(weight_and_bias)\n",
    "        #print(weight_and_bias.t().shape)\n",
    "        #print(x.shape)\n",
    "        #print(self.weight.size())\n",
    "        \n",
    "        out = x.matmul(weight_and_bias.t())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting a model for our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = MyModel(input_dim, output_dim)\n",
    "\n",
    "#model(torch.rand([5,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "Often called loss or error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        print(predictions)\n",
    "        print(targets)\n",
    "        \n",
    "        diff = torch.sub(predictions, targets)\n",
    "        diff2 = torch.pow(diff, 2)\n",
    "        err = torch.sum(diff2)\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = MyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimizing the cost function\n",
    "\n",
    "In other words training (or learning from data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0\n",
      "tensor([[-1.1168],\n",
      "        [-1.5429],\n",
      "        [-0.2646],\n",
      "        [-1.4008]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [ 4.8596],\n",
      "        [-0.0810],\n",
      "        [ 3.6039]])\n",
      "\tBatch = 0, Error = 81.63423156738281\n",
      "tensor([[3.1681],\n",
      "        [5.2494],\n",
      "        [4.2087],\n",
      "        [7.3307]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.1744],\n",
      "        [1.0966],\n",
      "        [3.2023]])\n",
      "\tBatch = 1, Error = 38.63407897949219\n",
      "tensor([[0.2505],\n",
      "        [0.6924]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [1.1995]])\n",
      "\tBatch = 2, Error = 0.2644203007221222\n",
      "tensor([[0.7257],\n",
      "        [1.1784],\n",
      "        [0.2730],\n",
      "        [3.4418]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [1.6029],\n",
      "        [0.3358],\n",
      "        [3.6039]])\n",
      "tensor([[2.2807],\n",
      "        [3.2559],\n",
      "        [4.2311],\n",
      "        [2.7683]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [3.2023],\n",
      "        [4.8596],\n",
      "        [2.8280]])\n",
      "tensor([[ 2.0029],\n",
      "        [-0.1466]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.0966],\n",
      "        [-0.0810]])\n",
      "tensor([[3.8529],\n",
      "        [1.8447],\n",
      "        [4.3549],\n",
      "        [3.3509]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [1.0966],\n",
      "        [4.8596],\n",
      "        [3.2023]])\n",
      "tensor([[ 2.2617],\n",
      "        [ 0.7989],\n",
      "        [ 0.3113],\n",
      "        [-0.1763]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.1744],\n",
      "        [ 1.1995],\n",
      "        [ 0.3358],\n",
      "        [-0.0810]])\n",
      "tensor([[2.7807],\n",
      "        [1.3066]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [1.6029]])\n",
      "tensor([[1.8505],\n",
      "        [2.3534],\n",
      "        [0.8449],\n",
      "        [2.8562]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [2.1744],\n",
      "        [1.1995],\n",
      "        [2.8280]])\n",
      "tensor([[3.5869],\n",
      "        [4.0568],\n",
      "        [3.1169],\n",
      "        [1.2370]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [4.8596],\n",
      "        [3.2023],\n",
      "        [1.6029]])\n",
      "tensor([[ 0.4108],\n",
      "        [-0.1474]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [-0.0810]])\n",
      "tensor([[ 4.3125],\n",
      "        [ 1.5249],\n",
      "        [ 0.4099],\n",
      "        [-0.1476]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.6039],\n",
      "        [ 1.6029],\n",
      "        [ 0.3358],\n",
      "        [-0.0810]])\n",
      "tensor([[2.3587],\n",
      "        [4.3739],\n",
      "        [2.8625],\n",
      "        [3.3663]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [4.8596],\n",
      "        [2.8280],\n",
      "        [3.2023]])\n",
      "tensor([[0.8902],\n",
      "        [1.9386]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [1.0966]])\n",
      "tensor([[0.3285],\n",
      "        [4.3079],\n",
      "        [3.3131],\n",
      "        [1.8208]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [4.8596],\n",
      "        [3.2023],\n",
      "        [1.0966]])\n",
      "tensor([[ 3.9064],\n",
      "        [-0.1745],\n",
      "        [ 0.8457],\n",
      "        [ 2.3761]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.6039],\n",
      "        [-0.0810],\n",
      "        [ 1.1995],\n",
      "        [ 2.1744]])\n",
      "tensor([[1.2751],\n",
      "        [2.7259]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.8280]])\n",
      "tensor([[-0.1670],\n",
      "        [ 2.3287],\n",
      "        [ 2.8278],\n",
      "        [ 0.3321]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 2.1744],\n",
      "        [ 2.8280],\n",
      "        [ 0.3358]])\n",
      "tensor([[1.7984],\n",
      "        [4.2567],\n",
      "        [1.3067],\n",
      "        [3.7650]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [4.8596],\n",
      "        [1.6029],\n",
      "        [3.6039]])\n",
      "tensor([[0.8590],\n",
      "        [3.4255]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [3.2023]])\n",
      "tensor([[1.3489],\n",
      "        [2.3583],\n",
      "        [0.3395],\n",
      "        [0.8442]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.1744],\n",
      "        [0.3358],\n",
      "        [1.1995]])\n",
      "tensor([[3.9237],\n",
      "        [3.4136],\n",
      "        [4.4338],\n",
      "        [2.9036]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [3.2023],\n",
      "        [4.8596],\n",
      "        [2.8280]])\n",
      "tensor([[ 1.8541],\n",
      "        [-0.1604]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.0966],\n",
      "        [-0.0810]])\n",
      "tensor([[-0.1740],\n",
      "        [ 4.0929],\n",
      "        [ 1.7224],\n",
      "        [ 3.1447]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 4.8596],\n",
      "        [ 1.0966],\n",
      "        [ 3.2023]])\n",
      "tensor([[0.3527],\n",
      "        [0.8736],\n",
      "        [2.4363],\n",
      "        [2.9572]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [1.1995],\n",
      "        [2.1744],\n",
      "        [2.8280]])\n",
      "tensor([[3.8843],\n",
      "        [1.3505]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [1.6029]])\n",
      "tensor([[3.2756],\n",
      "        [3.7678],\n",
      "        [1.3065],\n",
      "        [0.8142]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [3.6039],\n",
      "        [1.6029],\n",
      "        [1.1995]])\n",
      "tensor([[-0.1615],\n",
      "        [ 2.7825],\n",
      "        [ 0.3292],\n",
      "        [ 1.8012]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 2.8280],\n",
      "        [ 0.3358],\n",
      "        [ 1.0966]])\n",
      "tensor([[2.1567],\n",
      "        [4.0203]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [4.8596]])\n",
      "Epoch = 10\n",
      "tensor([[4.1675],\n",
      "        [4.7080],\n",
      "        [0.9251],\n",
      "        [1.4655]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [4.8596],\n",
      "        [1.1995],\n",
      "        [1.6029]])\n",
      "\tBatch = 0, Error = 0.43496665358543396\n",
      "tensor([[ 3.4782],\n",
      "        [-0.1558],\n",
      "        [ 2.4399],\n",
      "        [ 2.9590]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.2023],\n",
      "        [-0.0810],\n",
      "        [ 2.1744],\n",
      "        [ 2.8280]])\n",
      "\tBatch = 1, Error = 0.1693500280380249\n",
      "tensor([[0.3120],\n",
      "        [1.7511]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [1.0966]])\n",
      "\tBatch = 2, Error = 0.4289027154445648\n",
      "tensor([[1.1829],\n",
      "        [2.5462],\n",
      "        [3.4550],\n",
      "        [3.9094]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.8280],\n",
      "        [3.6039],\n",
      "        [4.8596]])\n",
      "tensor([[ 2.1683],\n",
      "        [-0.1443],\n",
      "        [ 0.4338],\n",
      "        [ 3.9027]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.0966],\n",
      "        [-0.0810],\n",
      "        [ 0.3358],\n",
      "        [ 3.2023]])\n",
      "tensor([[2.2576],\n",
      "        [0.7948]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [1.1995]])\n",
      "tensor([[1.3003],\n",
      "        [1.7918],\n",
      "        [3.7576],\n",
      "        [3.2661]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [1.0966],\n",
      "        [3.6039],\n",
      "        [3.2023]])\n",
      "tensor([[2.0980],\n",
      "        [3.9254],\n",
      "        [2.5549],\n",
      "        [0.7275]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [4.8596],\n",
      "        [2.8280],\n",
      "        [1.1995]])\n",
      "tensor([[ 0.4166],\n",
      "        [-0.1511]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [-0.0810]])\n",
      "tensor([[3.2502],\n",
      "        [1.5494],\n",
      "        [0.4156],\n",
      "        [2.6833]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [1.6029],\n",
      "        [0.3358],\n",
      "        [2.1744]])\n",
      "tensor([[ 0.8659],\n",
      "        [ 3.4570],\n",
      "        [ 1.9024],\n",
      "        [-0.1705]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [ 3.2023],\n",
      "        [ 1.0966],\n",
      "        [-0.0810]])\n",
      "tensor([[4.1000],\n",
      "        [3.6241]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [3.6039]])\n",
      "tensor([[3.6184],\n",
      "        [1.4545],\n",
      "        [1.9955],\n",
      "        [2.5364]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [1.6029],\n",
      "        [1.0966],\n",
      "        [2.1744]])\n",
      "tensor([[ 3.9791],\n",
      "        [-0.1990],\n",
      "        [ 0.2652],\n",
      "        [ 2.5864]], grad_fn=<MmBackward>)\n",
      "tensor([[ 4.8596],\n",
      "        [-0.0810],\n",
      "        [ 0.3358],\n",
      "        [ 2.8280]])\n",
      "tensor([[4.2776],\n",
      "        [0.9398]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [1.1995]])\n",
      "tensor([[ 0.8366],\n",
      "        [ 2.3630],\n",
      "        [ 3.3807],\n",
      "        [-0.1811]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [ 2.1744],\n",
      "        [ 3.2023],\n",
      "        [-0.0810]])\n",
      "tensor([[2.7880],\n",
      "        [0.3154],\n",
      "        [1.7990],\n",
      "        [4.2716]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [0.3358],\n",
      "        [1.0966],\n",
      "        [4.8596]])\n",
      "tensor([[3.9899],\n",
      "        [1.3836]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [1.6029]])\n",
      "tensor([[1.3092],\n",
      "        [2.3043],\n",
      "        [0.3140],\n",
      "        [4.2946]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.1744],\n",
      "        [0.3358],\n",
      "        [4.8596]])\n",
      "tensor([[ 4.2284],\n",
      "        [ 2.0299],\n",
      "        [ 3.6788],\n",
      "        [-0.1686]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.6039],\n",
      "        [ 1.0966],\n",
      "        [ 3.2023],\n",
      "        [-0.0810]])\n",
      "tensor([[0.6565],\n",
      "        [2.3846]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [2.8280]])\n",
      "tensor([[ 4.0290],\n",
      "        [ 3.5605],\n",
      "        [-0.1878],\n",
      "        [ 2.6234]], grad_fn=<MmBackward>)\n",
      "tensor([[ 4.8596],\n",
      "        [ 3.6039],\n",
      "        [-0.0810],\n",
      "        [ 2.8280]])\n",
      "tensor([[1.5062],\n",
      "        [2.0629],\n",
      "        [0.3927],\n",
      "        [2.6197]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [1.0966],\n",
      "        [0.3358],\n",
      "        [2.1744]])\n",
      "tensor([[0.8078],\n",
      "        [3.3060]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [3.2023]])\n",
      "tensor([[2.8155],\n",
      "        [1.3149],\n",
      "        [3.8159],\n",
      "        [0.3145]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [1.6029],\n",
      "        [3.6039],\n",
      "        [0.3358]])\n",
      "tensor([[ 0.8025],\n",
      "        [ 1.7886],\n",
      "        [-0.1835],\n",
      "        [ 2.2816]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [ 1.0966],\n",
      "        [-0.0810],\n",
      "        [ 2.1744]])\n",
      "tensor([[3.0904],\n",
      "        [4.0276]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [4.8596]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1707],\n",
      "        [ 2.5753],\n",
      "        [ 4.7721],\n",
      "        [ 3.1245]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 2.1744],\n",
      "        [ 4.8596],\n",
      "        [ 2.8280]])\n",
      "tensor([[1.8989],\n",
      "        [0.3389],\n",
      "        [3.9789],\n",
      "        [1.3789]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [0.3358],\n",
      "        [3.6039],\n",
      "        [1.6029]])\n",
      "tensor([[0.7318],\n",
      "        [3.0617]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [3.2023]])\n",
      "Epoch = 20\n",
      "tensor([[ 0.2967],\n",
      "        [-0.1880],\n",
      "        [ 2.7202],\n",
      "        [ 3.2048]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [-0.0810],\n",
      "        [ 2.8280],\n",
      "        [ 3.2023]])\n",
      "\tBatch = 0, Error = 0.024611301720142365\n",
      "tensor([[3.7467],\n",
      "        [4.2379],\n",
      "        [0.7994],\n",
      "        [1.2906]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [4.8596],\n",
      "        [1.1995],\n",
      "        [1.6029]])\n",
      "\tBatch = 1, Error = 0.6645837426185608\n",
      "tensor([[2.0470],\n",
      "        [2.5986]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [2.1744]])\n",
      "\tBatch = 2, Error = 1.0831892490386963\n",
      "tensor([[ 3.2701],\n",
      "        [ 1.7886],\n",
      "        [ 0.3072],\n",
      "        [-0.1867]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.2023],\n",
      "        [ 1.0966],\n",
      "        [ 0.3358],\n",
      "        [-0.0810]])\n",
      "tensor([[0.7258],\n",
      "        [2.1133],\n",
      "        [3.5008],\n",
      "        [3.9632]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [2.1744],\n",
      "        [3.6039],\n",
      "        [4.8596]])\n",
      "tensor([[1.5157],\n",
      "        [3.1998]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.8280]])\n",
      "tensor([[3.6211],\n",
      "        [4.1633],\n",
      "        [4.7055],\n",
      "        [3.0790]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [3.6039],\n",
      "        [4.8596],\n",
      "        [2.8280]])\n",
      "tensor([[ 0.2731],\n",
      "        [ 0.7420],\n",
      "        [ 1.6796],\n",
      "        [-0.1957]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [ 1.1995],\n",
      "        [ 1.0966],\n",
      "        [-0.0810]])\n",
      "tensor([[2.0835],\n",
      "        [1.1722]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [1.6029]])\n",
      "tensor([[ 3.5970],\n",
      "        [-0.1842],\n",
      "        [ 2.1790],\n",
      "        [ 2.6517]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.6039],\n",
      "        [-0.0810],\n",
      "        [ 2.1744],\n",
      "        [ 2.8280]])\n",
      "tensor([[4.1709],\n",
      "        [1.7545],\n",
      "        [0.7880],\n",
      "        [3.2043]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [1.0966],\n",
      "        [1.1995],\n",
      "        [3.2023]])\n",
      "tensor([[1.4080],\n",
      "        [0.3562]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [0.3358]])\n",
      "tensor([[ 4.0852],\n",
      "        [-0.1663],\n",
      "        [ 0.8966],\n",
      "        [ 3.0223]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.6039],\n",
      "        [-0.0810],\n",
      "        [ 1.1995],\n",
      "        [ 2.8280]])\n",
      "tensor([[4.2239],\n",
      "        [1.7817],\n",
      "        [2.2702],\n",
      "        [0.3164]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [1.0966],\n",
      "        [2.1744],\n",
      "        [0.3358]])\n",
      "tensor([[3.4166],\n",
      "        [1.3645]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [1.6029]])\n",
      "tensor([[1.3420],\n",
      "        [2.3528],\n",
      "        [4.3742],\n",
      "        [1.8474]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.1744],\n",
      "        [4.8596],\n",
      "        [1.0966]])\n",
      "tensor([[ 2.9280],\n",
      "        [ 3.9632],\n",
      "        [-0.1777],\n",
      "        [ 0.3399]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [ 3.6039],\n",
      "        [-0.0810],\n",
      "        [ 0.3358]])\n",
      "tensor([[0.7824],\n",
      "        [3.2009]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [3.2023]])\n",
      "tensor([[-0.1767],\n",
      "        [ 3.7588],\n",
      "        [ 2.7749],\n",
      "        [ 1.2991]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 3.6039],\n",
      "        [ 2.8280],\n",
      "        [ 1.6029]])\n",
      "tensor([[0.3211],\n",
      "        [4.2558],\n",
      "        [3.2721],\n",
      "        [0.8129]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [4.8596],\n",
      "        [3.2023],\n",
      "        [1.1995]])\n",
      "tensor([[2.5866],\n",
      "        [2.0389]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [1.0966]])\n",
      "tensor([[1.7845],\n",
      "        [2.2754],\n",
      "        [3.2572],\n",
      "        [2.7663]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [2.1744],\n",
      "        [3.2023],\n",
      "        [2.8280]])\n",
      "tensor([[ 1.1823],\n",
      "        [ 3.9364],\n",
      "        [ 0.2643],\n",
      "        [-0.1948]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.6029],\n",
      "        [ 4.8596],\n",
      "        [ 0.3358],\n",
      "        [-0.0810]])\n",
      "tensor([[4.2599],\n",
      "        [0.9418]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [1.1995]])\n",
      "tensor([[2.8691],\n",
      "        [0.3347],\n",
      "        [1.8554],\n",
      "        [1.3485]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [0.3358],\n",
      "        [1.0966],\n",
      "        [1.6029]])\n",
      "tensor([[0.7816],\n",
      "        [2.2286],\n",
      "        [4.1580],\n",
      "        [3.1933]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [2.1744],\n",
      "        [4.8596],\n",
      "        [3.2023]])\n",
      "tensor([[ 4.2385],\n",
      "        [-0.1615]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.6039],\n",
      "        [-0.0810]])\n",
      "tensor([[0.3279],\n",
      "        [2.8305],\n",
      "        [2.3300],\n",
      "        [4.3320]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [2.8280],\n",
      "        [2.1744],\n",
      "        [4.8596]])\n",
      "tensor([[1.4524],\n",
      "        [3.6090],\n",
      "        [4.1482],\n",
      "        [1.9915]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [3.2023],\n",
      "        [3.6039],\n",
      "        [1.0966]])\n",
      "tensor([[-0.1990],\n",
      "        [ 0.6779]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 1.1995]])\n",
      "Epoch = 30\n",
      "tensor([[-0.1862],\n",
      "        [ 3.8515],\n",
      "        [ 0.7111],\n",
      "        [ 3.4029]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 4.8596],\n",
      "        [ 1.1995],\n",
      "        [ 3.6039]])\n",
      "\tBatch = 0, Error = 1.3064082860946655\n",
      "tensor([[2.6612],\n",
      "        [2.0990],\n",
      "        [0.4121],\n",
      "        [3.7858]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [1.0966],\n",
      "        [0.3358],\n",
      "        [3.2023]])\n",
      "\tBatch = 1, Error = 1.5879442691802979\n",
      "tensor([[1.1836],\n",
      "        [2.5603]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.8280]])\n",
      "\tBatch = 2, Error = 0.2474481165409088\n",
      "tensor([[3.7152],\n",
      "        [2.2547],\n",
      "        [0.7943],\n",
      "        [1.7679]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [2.1744],\n",
      "        [1.1995],\n",
      "        [1.0966]])\n",
      "tensor([[ 0.2674],\n",
      "        [ 3.9150],\n",
      "        [ 3.0031],\n",
      "        [-0.1885]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [ 4.8596],\n",
      "        [ 3.2023],\n",
      "        [-0.0810]])\n",
      "tensor([[1.4971],\n",
      "        [3.1563]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.8280]])\n",
      "tensor([[ 4.1291],\n",
      "        [ 4.6661],\n",
      "        [ 1.9813],\n",
      "        [-0.1666]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.6039],\n",
      "        [ 4.8596],\n",
      "        [ 1.0966],\n",
      "        [-0.0810]])\n",
      "tensor([[0.7678],\n",
      "        [3.1602],\n",
      "        [1.2463],\n",
      "        [2.2032]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [3.2023],\n",
      "        [1.6029],\n",
      "        [2.1744]])\n",
      "tensor([[0.3256],\n",
      "        [2.8196]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [2.8280]])\n",
      "tensor([[0.3266],\n",
      "        [3.3229],\n",
      "        [2.8235],\n",
      "        [1.8247]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [3.2023],\n",
      "        [2.8280],\n",
      "        [1.0966]])\n",
      "tensor([[ 2.1261],\n",
      "        [ 1.1998],\n",
      "        [ 0.7367],\n",
      "        [-0.1895]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.1744],\n",
      "        [ 1.6029],\n",
      "        [ 1.1995],\n",
      "        [-0.0810]])\n",
      "tensor([[4.2075],\n",
      "        [3.7212]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [3.6039]])\n",
      "tensor([[3.5821],\n",
      "        [1.9790],\n",
      "        [4.1164],\n",
      "        [0.9103]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [1.0966],\n",
      "        [3.6039],\n",
      "        [1.1995]])\n",
      "tensor([[ 2.4501],\n",
      "        [ 0.2516],\n",
      "        [-0.1881],\n",
      "        [ 2.0104]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [ 0.3358],\n",
      "        [-0.0810],\n",
      "        [ 2.1744]])\n",
      "tensor([[4.0621],\n",
      "        [1.2384]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [1.6029]])\n",
      "tensor([[1.5035],\n",
      "        [2.0548],\n",
      "        [3.1573],\n",
      "        [3.7085]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [1.0966],\n",
      "        [2.8280],\n",
      "        [3.2023]])\n",
      "tensor([[0.7419],\n",
      "        [3.5198],\n",
      "        [2.1309],\n",
      "        [0.2789]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [3.6039],\n",
      "        [2.1744],\n",
      "        [0.3358]])\n",
      "tensor([[-0.1712],\n",
      "        [ 4.1590]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 4.8596]])\n",
      "tensor([[1.4724],\n",
      "        [4.7280],\n",
      "        [0.3872],\n",
      "        [4.1854]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [4.8596],\n",
      "        [0.3358],\n",
      "        [3.6039]])\n",
      "tensor([[ 1.8856],\n",
      "        [ 2.9099],\n",
      "        [-0.1628],\n",
      "        [ 3.4220]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.0966],\n",
      "        [ 2.8280],\n",
      "        [-0.0810],\n",
      "        [ 3.2023]])\n",
      "tensor([[0.7401],\n",
      "        [2.1249]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [2.1744]])\n",
      "tensor([[ 1.2460],\n",
      "        [ 2.6648],\n",
      "        [-0.1728],\n",
      "        [ 4.0837]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.6029],\n",
      "        [ 2.8280],\n",
      "        [-0.0810],\n",
      "        [ 4.8596]])\n",
      "tensor([[0.9769],\n",
      "        [2.6599],\n",
      "        [3.7819],\n",
      "        [4.3429]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [2.1744],\n",
      "        [3.2023],\n",
      "        [3.6039]])\n",
      "tensor([[1.6013],\n",
      "        [0.2678]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [0.3358]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3674],\n",
      "        [2.7929],\n",
      "        [1.9420],\n",
      "        [0.6655]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [3.2023],\n",
      "        [2.1744],\n",
      "        [1.1995]])\n",
      "tensor([[0.3494],\n",
      "        [4.3661],\n",
      "        [1.8556],\n",
      "        [1.3536]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [4.8596],\n",
      "        [1.0966],\n",
      "        [1.6029]])\n",
      "tensor([[-0.1533],\n",
      "        [ 4.0303]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 3.6039]])\n",
      "tensor([[-0.1604],\n",
      "        [ 4.2469],\n",
      "        [ 3.7572],\n",
      "        [ 2.2881]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 4.8596],\n",
      "        [ 3.6039],\n",
      "        [ 2.1744]])\n",
      "tensor([[1.9520],\n",
      "        [0.3741],\n",
      "        [3.5298],\n",
      "        [0.9000]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [0.3358],\n",
      "        [3.2023],\n",
      "        [1.1995]])\n",
      "tensor([[2.6840],\n",
      "        [1.2569]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [1.6029]])\n",
      "Epoch = 40\n",
      "tensor([[ 2.8051],\n",
      "        [-0.1605],\n",
      "        [ 1.3223],\n",
      "        [ 0.3338]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [-0.0810],\n",
      "        [ 1.6029],\n",
      "        [ 0.3358]])\n",
      "\tBatch = 0, Error = 0.08559315651655197\n",
      "tensor([[2.3663],\n",
      "        [3.8778],\n",
      "        [3.3740],\n",
      "        [0.8548]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [3.6039],\n",
      "        [3.2023],\n",
      "        [1.1995]])\n",
      "\tBatch = 1, Error = 0.2601599097251892\n",
      "tensor([[4.0544],\n",
      "        [1.7138]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [1.0966]])\n",
      "\tBatch = 2, Error = 1.0293678045272827\n",
      "tensor([[3.9627],\n",
      "        [2.9333],\n",
      "        [1.3892],\n",
      "        [0.3598]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [2.8280],\n",
      "        [1.6029],\n",
      "        [0.3358]])\n",
      "tensor([[ 2.2725],\n",
      "        [-0.1604],\n",
      "        [ 3.2456],\n",
      "        [ 0.8128]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.1744],\n",
      "        [-0.0810],\n",
      "        [ 3.2023],\n",
      "        [ 1.1995]])\n",
      "tensor([[4.2235],\n",
      "        [1.7916]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [1.0966]])\n",
      "tensor([[1.3902],\n",
      "        [3.9656],\n",
      "        [3.4505],\n",
      "        [0.8751]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [3.6039],\n",
      "        [3.2023],\n",
      "        [1.1995]])\n",
      "tensor([[ 1.7734],\n",
      "        [ 2.2559],\n",
      "        [-0.1565],\n",
      "        [ 0.3260]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.0966],\n",
      "        [ 2.1744],\n",
      "        [-0.0810],\n",
      "        [ 0.3358]])\n",
      "tensor([[3.9000],\n",
      "        [2.5433]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [2.8280]])\n",
      "tensor([[3.7263],\n",
      "        [0.4080],\n",
      "        [3.1732],\n",
      "        [4.8324]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [0.3358],\n",
      "        [2.8280],\n",
      "        [4.8596]])\n",
      "tensor([[2.3306],\n",
      "        [1.3330],\n",
      "        [1.8318],\n",
      "        [3.8270]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [1.6029],\n",
      "        [1.0966],\n",
      "        [3.6039]])\n",
      "tensor([[ 0.7258],\n",
      "        [-0.1803]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [-0.0810]])\n",
      "tensor([[0.7557],\n",
      "        [3.9914],\n",
      "        [2.6047],\n",
      "        [1.6802]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [4.8596],\n",
      "        [2.8280],\n",
      "        [1.0966]])\n",
      "tensor([[ 1.4624],\n",
      "        [ 2.5371],\n",
      "        [-0.1498],\n",
      "        [ 0.3876]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.6029],\n",
      "        [ 2.1744],\n",
      "        [-0.0810],\n",
      "        [ 0.3358]])\n",
      "tensor([[3.5092],\n",
      "        [4.0326]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [3.6039]])\n",
      "tensor([[1.7071],\n",
      "        [1.2382],\n",
      "        [2.1760],\n",
      "        [3.1139]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [1.6029],\n",
      "        [2.1744],\n",
      "        [3.2023]])\n",
      "tensor([[ 3.9839],\n",
      "        [ 0.7517],\n",
      "        [-0.1718],\n",
      "        [ 2.5987]], grad_fn=<MmBackward>)\n",
      "tensor([[ 4.8596],\n",
      "        [ 1.1995],\n",
      "        [-0.0810],\n",
      "        [ 2.8280]])\n",
      "tensor([[0.4218],\n",
      "        [4.3468]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [3.6039]])\n",
      "tensor([[1.8523],\n",
      "        [3.3581],\n",
      "        [4.3620],\n",
      "        [2.3542]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [3.2023],\n",
      "        [4.8596],\n",
      "        [2.1744]])\n",
      "tensor([[0.8261],\n",
      "        [0.3294],\n",
      "        [1.3229],\n",
      "        [2.8131]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [0.3358],\n",
      "        [1.6029],\n",
      "        [2.8280]])\n",
      "tensor([[ 3.9513],\n",
      "        [-0.1539]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.6039],\n",
      "        [-0.0810]])\n",
      "tensor([[ 0.3267],\n",
      "        [-0.1594],\n",
      "        [ 2.2709],\n",
      "        [ 1.2988]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [-0.0810],\n",
      "        [ 2.1744],\n",
      "        [ 1.6029]])\n",
      "tensor([[4.2595],\n",
      "        [0.8272],\n",
      "        [3.2789],\n",
      "        [1.8079]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [1.1995],\n",
      "        [3.2023],\n",
      "        [1.0966]])\n",
      "tensor([[2.9539],\n",
      "        [3.9885]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [3.6039]])\n",
      "tensor([[-0.1600],\n",
      "        [ 0.7999],\n",
      "        [ 2.2396],\n",
      "        [ 1.2798]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 1.1995],\n",
      "        [ 2.1744],\n",
      "        [ 1.6029]])\n",
      "tensor([[3.8066],\n",
      "        [3.3126],\n",
      "        [2.8187],\n",
      "        [1.8307]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [3.2023],\n",
      "        [2.8280],\n",
      "        [1.0966]])\n",
      "tensor([[0.2766],\n",
      "        [3.8171]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [4.8596]])\n",
      "tensor([[1.9945],\n",
      "        [0.3906],\n",
      "        [0.9252],\n",
      "        [3.5983]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [0.3358],\n",
      "        [1.1995],\n",
      "        [3.2023]])\n",
      "tensor([[2.6989],\n",
      "        [3.6537],\n",
      "        [4.1311],\n",
      "        [1.2667]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [3.6039],\n",
      "        [4.8596],\n",
      "        [1.6029]])\n",
      "tensor([[-0.1426],\n",
      "        [ 2.6315]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 2.1744]])\n",
      "Epoch = 50\n",
      "tensor([[ 0.9146],\n",
      "        [ 3.5772],\n",
      "        [ 1.4471],\n",
      "        [-0.1505]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [ 3.2023],\n",
      "        [ 1.6029],\n",
      "        [-0.0810]])\n",
      "\tBatch = 0, Error = 0.2508792579174042\n",
      "tensor([[4.5057],\n",
      "        [2.9546],\n",
      "        [3.9887],\n",
      "        [1.9205]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [2.8280],\n",
      "        [3.6039],\n",
      "        [1.0966]])\n",
      "\tBatch = 1, Error = 0.9680540561676025\n",
      "tensor([[2.2254],\n",
      "        [0.3112]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [0.3358]])\n",
      "\tBatch = 2, Error = 0.0032079913653433323\n",
      "tensor([[-0.1679],\n",
      "        [ 1.7374],\n",
      "        [ 1.2610],\n",
      "        [ 0.7847]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 1.0966],\n",
      "        [ 1.6029],\n",
      "        [ 1.1995]])\n",
      "tensor([[2.6527],\n",
      "        [3.1221],\n",
      "        [3.5915],\n",
      "        [0.3056]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [3.2023],\n",
      "        [3.6039],\n",
      "        [0.3358]])\n",
      "tensor([[4.2197],\n",
      "        [2.2741]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [2.1744]])\n",
      "tensor([[ 0.9283],\n",
      "        [-0.1471],\n",
      "        [ 3.0790],\n",
      "        [ 4.1544]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [-0.0810],\n",
      "        [ 2.8280],\n",
      "        [ 3.6039]])\n",
      "tensor([[2.2704],\n",
      "        [4.2119],\n",
      "        [0.3290],\n",
      "        [1.2997]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [4.8596],\n",
      "        [0.3358],\n",
      "        [1.6029]])\n",
      "tensor([[3.6860],\n",
      "        [2.0466]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [1.0966]])\n",
      "tensor([[2.2142],\n",
      "        [4.1198],\n",
      "        [3.6434],\n",
      "        [3.1670]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [4.8596],\n",
      "        [3.6039],\n",
      "        [3.2023]])\n",
      "tensor([[0.3848],\n",
      "        [2.0009],\n",
      "        [0.9235],\n",
      "        [1.4622]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [1.0966],\n",
      "        [1.1995],\n",
      "        [1.6029]])\n",
      "tensor([[-0.1646],\n",
      "        [ 2.9101]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 2.8280]])\n",
      "tensor([[-0.1646],\n",
      "        [ 0.8507],\n",
      "        [ 3.8966],\n",
      "        [ 4.4043]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 1.1995],\n",
      "        [ 3.6039],\n",
      "        [ 4.8596]])\n",
      "tensor([[3.0367],\n",
      "        [2.5052],\n",
      "        [3.5683],\n",
      "        [0.3789]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [2.1744],\n",
      "        [3.2023],\n",
      "        [0.3358]])\n",
      "tensor([[1.2619],\n",
      "        [1.7397]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [1.0966]])\n",
      "tensor([[2.5988],\n",
      "        [0.2850],\n",
      "        [3.5243],\n",
      "        [3.9870]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [0.3358],\n",
      "        [3.6039],\n",
      "        [4.8596]])\n",
      "tensor([[0.9657],\n",
      "        [1.5252],\n",
      "        [2.0846],\n",
      "        [2.6440]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [1.6029],\n",
      "        [1.0966],\n",
      "        [2.1744]])\n",
      "tensor([[-0.1760],\n",
      "        [ 3.3579]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 3.2023]])\n",
      "tensor([[ 0.3170],\n",
      "        [ 3.2823],\n",
      "        [ 2.7881],\n",
      "        [-0.1772]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [ 3.2023],\n",
      "        [ 2.8280],\n",
      "        [-0.0810]])\n",
      "tensor([[3.7545],\n",
      "        [1.2981],\n",
      "        [0.8068],\n",
      "        [4.2457]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [1.6029],\n",
      "        [1.1995],\n",
      "        [4.8596]])\n",
      "tensor([[2.0473],\n",
      "        [2.5973]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [2.1744]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2814],\n",
      "        [0.3123],\n",
      "        [1.7891],\n",
      "        [2.7737]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [0.3358],\n",
      "        [1.0966],\n",
      "        [2.8280]])\n",
      "tensor([[ 1.1960],\n",
      "        [-0.1944],\n",
      "        [ 3.0498],\n",
      "        [ 3.9768]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.6029],\n",
      "        [-0.0810],\n",
      "        [ 3.2023],\n",
      "        [ 4.8596]])\n",
      "tensor([[4.3425],\n",
      "        [0.9631]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [1.1995]])\n",
      "tensor([[3.3983],\n",
      "        [0.3369],\n",
      "        [4.4187],\n",
      "        [1.3574]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [0.3358],\n",
      "        [4.8596],\n",
      "        [1.6029]])\n",
      "tensor([[0.9219],\n",
      "        [4.1781],\n",
      "        [2.5500],\n",
      "        [2.0073]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [3.6039],\n",
      "        [2.1744],\n",
      "        [1.0966]])\n",
      "tensor([[ 2.5020],\n",
      "        [-0.1952]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [-0.0810]])\n",
      "tensor([[4.0310],\n",
      "        [3.5624],\n",
      "        [2.1566],\n",
      "        [2.6252]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [3.6039],\n",
      "        [2.1744],\n",
      "        [2.8280]])\n",
      "tensor([[ 0.3927],\n",
      "        [ 3.7363],\n",
      "        [-0.1646],\n",
      "        [ 2.0645]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [ 3.2023],\n",
      "        [-0.0810],\n",
      "        [ 1.0966]])\n",
      "tensor([[1.2535],\n",
      "        [0.7710]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [1.1995]])\n",
      "Epoch = 60\n",
      "tensor([[2.3270],\n",
      "        [1.3248],\n",
      "        [2.8281],\n",
      "        [3.3292]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [1.6029],\n",
      "        [2.8280],\n",
      "        [3.2023]])\n",
      "\tBatch = 0, Error = 0.11673558503389359\n",
      "tensor([[ 0.3146],\n",
      "        [ 3.7665],\n",
      "        [ 0.8077],\n",
      "        [-0.1786]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [ 3.6039],\n",
      "        [ 1.1995],\n",
      "        [-0.0810]])\n",
      "\tBatch = 1, Error = 0.18994870781898499\n",
      "tensor([[4.2231],\n",
      "        [1.7816]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [1.0966]])\n",
      "\tBatch = 2, Error = 0.8744015693664551\n",
      "tensor([[0.3449],\n",
      "        [2.4146],\n",
      "        [1.3797],\n",
      "        [4.4843]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [2.1744],\n",
      "        [1.6029],\n",
      "        [4.8596]])\n",
      "tensor([[4.1951],\n",
      "        [3.6500],\n",
      "        [3.1050],\n",
      "        [2.0148]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [3.2023],\n",
      "        [2.8280],\n",
      "        [1.0966]])\n",
      "tensor([[-0.2103],\n",
      "        [ 0.6226]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 1.1995]])\n",
      "tensor([[ 3.6529],\n",
      "        [ 1.5146],\n",
      "        [ 2.7976],\n",
      "        [-0.1962]], grad_fn=<MmBackward>)\n",
      "tensor([[ 4.8596],\n",
      "        [ 1.0966],\n",
      "        [ 3.2023],\n",
      "        [-0.0810]])\n",
      "tensor([[3.0992],\n",
      "        [1.4646],\n",
      "        [0.9197],\n",
      "        [4.1889]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [1.6029],\n",
      "        [1.1995],\n",
      "        [3.6039]])\n",
      "tensor([[0.3141],\n",
      "        [2.2856]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [2.1744]])\n",
      "tensor([[ 3.2331],\n",
      "        [ 0.3071],\n",
      "        [-0.1805],\n",
      "        [ 2.7455]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.2023],\n",
      "        [ 0.3358],\n",
      "        [-0.0810],\n",
      "        [ 2.8280]])\n",
      "tensor([[1.7857],\n",
      "        [3.7484],\n",
      "        [1.2951],\n",
      "        [4.2391]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [3.6039],\n",
      "        [1.6029],\n",
      "        [4.8596]])\n",
      "tensor([[0.8569],\n",
      "        [2.4048]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [2.1744]])\n",
      "tensor([[2.3843],\n",
      "        [3.4072],\n",
      "        [1.8729],\n",
      "        [3.9186]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [3.2023],\n",
      "        [1.0966],\n",
      "        [3.6039]])\n",
      "tensor([[0.2295],\n",
      "        [3.6887],\n",
      "        [0.6619],\n",
      "        [2.3915]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [4.8596],\n",
      "        [1.1995],\n",
      "        [2.8280]])\n",
      "tensor([[ 1.5586],\n",
      "        [-0.1579]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.6029],\n",
      "        [-0.0810]])\n",
      "tensor([[2.1384],\n",
      "        [2.7119],\n",
      "        [4.4323],\n",
      "        [5.0057]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [2.1744],\n",
      "        [3.6039],\n",
      "        [4.8596]])\n",
      "tensor([[ 2.3689],\n",
      "        [ 2.7981],\n",
      "        [ 1.0812],\n",
      "        [-0.2065]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [ 3.2023],\n",
      "        [ 1.6029],\n",
      "        [-0.0810]])\n",
      "tensor([[0.3226],\n",
      "        [0.8215]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [1.1995]])\n",
      "tensor([[0.3379],\n",
      "        [1.3508],\n",
      "        [1.8572],\n",
      "        [2.3636]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [1.6029],\n",
      "        [1.0966],\n",
      "        [2.1744]])\n",
      "tensor([[ 3.6167],\n",
      "        [-0.1825],\n",
      "        [ 4.0916],\n",
      "        [ 0.7673]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.6039],\n",
      "        [-0.0810],\n",
      "        [ 4.8596],\n",
      "        [ 1.1995]])\n",
      "tensor([[3.1415],\n",
      "        [3.6912]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [3.2023]])\n",
      "tensor([[2.8153],\n",
      "        [3.8113],\n",
      "        [0.3252],\n",
      "        [0.8232]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [3.6039],\n",
      "        [0.3358],\n",
      "        [1.1995]])\n",
      "tensor([[-0.1689],\n",
      "        [ 1.3011],\n",
      "        [ 2.2811],\n",
      "        [ 3.2612]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 1.6029],\n",
      "        [ 2.1744],\n",
      "        [ 3.2023]])\n",
      "tensor([[1.7940],\n",
      "        [4.2421]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [4.8596]])\n",
      "tensor([[-0.1660],\n",
      "        [ 1.3838],\n",
      "        [ 3.4502],\n",
      "        [ 0.8672]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 1.6029],\n",
      "        [ 3.2023],\n",
      "        [ 1.1995]])\n",
      "tensor([[4.4549],\n",
      "        [3.9423],\n",
      "        [0.3543],\n",
      "        [2.9172]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [3.6039],\n",
      "        [0.3358],\n",
      "        [2.8280]])\n",
      "tensor([[1.9061],\n",
      "        [2.4224]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [2.1744]])\n",
      "tensor([[2.1830],\n",
      "        [4.0736],\n",
      "        [3.6009],\n",
      "        [1.2377]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [4.8596],\n",
      "        [3.6039],\n",
      "        [1.6029]])\n",
      "tensor([[ 3.7074],\n",
      "        [-0.1573],\n",
      "        [ 0.9469],\n",
      "        [ 3.1553]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.2023],\n",
      "        [-0.0810],\n",
      "        [ 1.1995],\n",
      "        [ 2.8280]])\n",
      "tensor([[0.3360],\n",
      "        [1.8463]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [1.0966]])\n",
      "Epoch = 70\n",
      "tensor([[ 2.6627],\n",
      "        [ 4.0853],\n",
      "        [ 3.6111],\n",
      "        [-0.1824]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [ 4.8596],\n",
      "        [ 3.6039],\n",
      "        [-0.0810]])\n",
      "\tBatch = 0, Error = 0.6372606754302979\n",
      "tensor([[2.0432],\n",
      "        [3.6968],\n",
      "        [1.4919],\n",
      "        [0.9407]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [3.2023],\n",
      "        [1.6029],\n",
      "        [1.1995]])\n",
      "\tBatch = 1, Error = 1.219813585281372\n",
      "tensor([[2.2612],\n",
      "        [0.3057]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [0.3358]])\n",
      "\tBatch = 2, Error = 0.008424060419201851\n",
      "tensor([[2.7253],\n",
      "        [4.1801],\n",
      "        [2.2403],\n",
      "        [3.6951]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [4.8596],\n",
      "        [2.1744],\n",
      "        [3.6039]])\n",
      "tensor([[ 0.3684],\n",
      "        [-0.1718],\n",
      "        [ 3.6098],\n",
      "        [ 1.9891]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [-0.0810],\n",
      "        [ 3.2023],\n",
      "        [ 1.0966]])\n",
      "tensor([[1.2353],\n",
      "        [0.7580]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [1.1995]])\n",
      "tensor([[2.7995],\n",
      "        [1.3095],\n",
      "        [4.2895],\n",
      "        [0.8129]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [1.6029],\n",
      "        [4.8596],\n",
      "        [1.1995]])\n",
      "tensor([[ 3.7963],\n",
      "        [ 0.4096],\n",
      "        [ 4.3608],\n",
      "        [-0.1549]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.2023],\n",
      "        [ 0.3358],\n",
      "        [ 3.6039],\n",
      "        [-0.0810]])\n",
      "tensor([[1.6748],\n",
      "        [2.1390]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [2.1744]])\n",
      "tensor([[-0.1927],\n",
      "        [ 3.3541],\n",
      "        [ 2.9108],\n",
      "        [ 0.6940]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 3.6039],\n",
      "        [ 3.2023],\n",
      "        [ 1.1995]])\n",
      "tensor([[1.8008],\n",
      "        [0.3230],\n",
      "        [2.7859],\n",
      "        [2.2933]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [0.3358],\n",
      "        [2.8280],\n",
      "        [2.1744]])\n",
      "tensor([[1.2008],\n",
      "        [3.9723]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [4.8596]])\n",
      "tensor([[3.7015],\n",
      "        [4.8045],\n",
      "        [3.1500],\n",
      "        [0.3924]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [4.8596],\n",
      "        [2.8280],\n",
      "        [0.3358]])\n",
      "tensor([[ 0.8302],\n",
      "        [ 3.8477],\n",
      "        [-0.1756],\n",
      "        [ 2.3389]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [ 3.6039],\n",
      "        [-0.0810],\n",
      "        [ 2.1744]])\n",
      "tensor([[1.2747],\n",
      "        [1.7578]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [1.0966]])\n",
      "tensor([[0.2857],\n",
      "        [3.5540],\n",
      "        [1.6864],\n",
      "        [1.2195]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [3.6039],\n",
      "        [1.0966],\n",
      "        [1.6029]])\n",
      "tensor([[-0.1833],\n",
      "        [ 3.9521],\n",
      "        [ 3.0331],\n",
      "        [ 2.5736]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 4.8596],\n",
      "        [ 3.2023],\n",
      "        [ 2.8280]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9764],\n",
      "        [2.6730]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [2.1744]])\n",
      "tensor([[1.4766],\n",
      "        [3.1133],\n",
      "        [2.5677],\n",
      "        [0.3855]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.8280],\n",
      "        [2.1744],\n",
      "        [0.3358]])\n",
      "tensor([[-0.1722],\n",
      "        [ 4.4442],\n",
      "        [ 1.8795],\n",
      "        [ 0.8537]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 4.8596],\n",
      "        [ 1.0966],\n",
      "        [ 1.1995]])\n",
      "tensor([[4.0340],\n",
      "        [3.5084]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [3.2023]])\n",
      "tensor([[ 0.7568],\n",
      "        [-0.1855],\n",
      "        [ 2.6415],\n",
      "        [ 2.1703]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [-0.0810],\n",
      "        [ 2.8280],\n",
      "        [ 2.1744]])\n",
      "tensor([[3.2656],\n",
      "        [1.3020],\n",
      "        [0.3202],\n",
      "        [1.7929]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [1.6029],\n",
      "        [0.3358],\n",
      "        [1.0966]])\n",
      "tensor([[3.5675],\n",
      "        [4.0359]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [4.8596]])\n",
      "tensor([[ 4.7290],\n",
      "        [ 2.0116],\n",
      "        [ 1.4681],\n",
      "        [-0.1624]], grad_fn=<MmBackward>)\n",
      "tensor([[ 4.8596],\n",
      "        [ 1.0966],\n",
      "        [ 1.6029],\n",
      "        [-0.0810]])\n",
      "tensor([[3.4888],\n",
      "        [4.0120],\n",
      "        [2.9655],\n",
      "        [0.3495]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [3.6039],\n",
      "        [2.8280],\n",
      "        [0.3358]])\n",
      "tensor([[2.1276],\n",
      "        [0.7366]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [1.1995]])\n",
      "tensor([[ 2.1944],\n",
      "        [ 1.2444],\n",
      "        [-0.1805],\n",
      "        [ 0.2945]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.1744],\n",
      "        [ 1.6029],\n",
      "        [-0.0810],\n",
      "        [ 0.3358]])\n",
      "tensor([[3.7082],\n",
      "        [3.2233],\n",
      "        [1.7686],\n",
      "        [2.7384]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [3.2023],\n",
      "        [1.0966],\n",
      "        [2.8280]])\n",
      "tensor([[0.7237],\n",
      "        [3.9041]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [4.8596]])\n",
      "Epoch = 80\n",
      "tensor([[3.1283],\n",
      "        [2.0334],\n",
      "        [4.2232],\n",
      "        [0.3910]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [1.0966],\n",
      "        [3.6039],\n",
      "        [0.3358]])\n",
      "\tBatch = 0, Error = 1.3544514179229736\n",
      "tensor([[ 3.8061],\n",
      "        [ 2.0280],\n",
      "        [-0.1947],\n",
      "        [ 2.9170]], grad_fn=<MmBackward>)\n",
      "tensor([[ 4.8596],\n",
      "        [ 2.1744],\n",
      "        [-0.0810],\n",
      "        [ 3.2023]])\n",
      "\tBatch = 1, Error = 1.2257221937179565\n",
      "tensor([[0.9644],\n",
      "        [1.5280]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [1.6029]])\n",
      "\tBatch = 2, Error = 0.06088339537382126\n",
      "tensor([[4.9765],\n",
      "        [2.6952],\n",
      "        [1.5545],\n",
      "        [4.4062]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [2.1744],\n",
      "        [1.6029],\n",
      "        [3.6039]])\n",
      "tensor([[3.1305],\n",
      "        [0.2892],\n",
      "        [0.7628],\n",
      "        [2.6570]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [0.3358],\n",
      "        [1.1995],\n",
      "        [2.8280]])\n",
      "tensor([[ 1.8199],\n",
      "        [-0.1698]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.0966],\n",
      "        [-0.0810]])\n",
      "tensor([[0.7559],\n",
      "        [3.1020],\n",
      "        [2.1636],\n",
      "        [4.0404]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [3.2023],\n",
      "        [2.1744],\n",
      "        [4.8596]])\n",
      "tensor([[0.4021],\n",
      "        [3.1876],\n",
      "        [2.0734],\n",
      "        [4.3018]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [2.8280],\n",
      "        [1.0966],\n",
      "        [3.6039]])\n",
      "tensor([[ 1.1317],\n",
      "        [-0.1970]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.6029],\n",
      "        [-0.0810]])\n",
      "tensor([[0.2714],\n",
      "        [3.9249],\n",
      "        [2.5549],\n",
      "        [1.1848]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [4.8596],\n",
      "        [2.8280],\n",
      "        [1.6029]])\n",
      "tensor([[ 2.6861],\n",
      "        [ 2.1186],\n",
      "        [-0.1515],\n",
      "        [ 4.3887]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.1744],\n",
      "        [ 1.0966],\n",
      "        [-0.0810],\n",
      "        [ 3.6039]])\n",
      "tensor([[0.6866],\n",
      "        [2.8943]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [3.2023]])\n",
      "tensor([[3.1278],\n",
      "        [2.1827],\n",
      "        [3.6003],\n",
      "        [4.0729]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [2.1744],\n",
      "        [3.6039],\n",
      "        [4.8596]])\n",
      "tensor([[3.1162],\n",
      "        [2.0232],\n",
      "        [0.3836],\n",
      "        [1.4767]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [1.0966],\n",
      "        [0.3358],\n",
      "        [1.6029]])\n",
      "tensor([[ 0.8079],\n",
      "        [-0.1856]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [-0.0810]])\n",
      "tensor([[3.3550],\n",
      "        [0.8331],\n",
      "        [2.3463],\n",
      "        [3.8594]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [1.1995],\n",
      "        [2.1744],\n",
      "        [3.6039]])\n",
      "tensor([[-0.1800],\n",
      "        [ 0.2928],\n",
      "        [ 4.0753],\n",
      "        [ 1.2385]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 0.3358],\n",
      "        [ 4.8596],\n",
      "        [ 1.6029]])\n",
      "tensor([[2.0566],\n",
      "        [3.1620]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [2.8280]])\n",
      "tensor([[ 0.8114],\n",
      "        [-0.1800],\n",
      "        [ 1.8029],\n",
      "        [ 2.7943]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [-0.0810],\n",
      "        [ 1.0966],\n",
      "        [ 2.8280]])\n",
      "tensor([[0.2940],\n",
      "        [2.2049],\n",
      "        [3.1603],\n",
      "        [4.1158]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [2.1744],\n",
      "        [3.2023],\n",
      "        [4.8596]])\n",
      "tensor([[4.1904],\n",
      "        [1.4665]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [1.6029]])\n",
      "tensor([[ 0.3262],\n",
      "        [-0.1768],\n",
      "        [ 3.3443],\n",
      "        [ 1.3323]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [-0.0810],\n",
      "        [ 3.2023],\n",
      "        [ 1.6029]])\n",
      "tensor([[1.8332],\n",
      "        [4.3399],\n",
      "        [2.8359],\n",
      "        [0.8305]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [4.8596],\n",
      "        [2.8280],\n",
      "        [1.1995]])\n",
      "tensor([[2.4555],\n",
      "        [4.0303]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [3.6039]])\n",
      "tensor([[0.7726],\n",
      "        [1.2506],\n",
      "        [0.2946],\n",
      "        [4.1185]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [1.6029],\n",
      "        [0.3358],\n",
      "        [4.8596]])\n",
      "tensor([[-0.1522],\n",
      "        [ 2.0960],\n",
      "        [ 4.3441],\n",
      "        [ 2.6580]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 1.0966],\n",
      "        [ 3.6039],\n",
      "        [ 2.1744]])\n",
      "tensor([[2.4554],\n",
      "        [2.8972]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [3.2023]])\n",
      "tensor([[4.1778],\n",
      "        [3.2090],\n",
      "        [0.7871],\n",
      "        [0.3027]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [3.2023],\n",
      "        [1.1995],\n",
      "        [0.3358]])\n",
      "tensor([[-0.1592],\n",
      "        [ 2.0492],\n",
      "        [ 3.1534],\n",
      "        [ 4.2576]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 1.0966],\n",
      "        [ 2.8280],\n",
      "        [ 3.6039]])\n",
      "tensor([[1.1385],\n",
      "        [2.0285]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [2.1744]])\n",
      "Epoch = 90\n",
      "tensor([[3.5411],\n",
      "        [3.0754],\n",
      "        [0.7472],\n",
      "        [2.1441]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [3.2023],\n",
      "        [1.1995],\n",
      "        [2.1744]])\n",
      "\tBatch = 0, Error = 0.22556975483894348\n",
      "tensor([[ 2.7663],\n",
      "        [ 0.3188],\n",
      "        [ 1.7873],\n",
      "        [-0.1706]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [ 0.3358],\n",
      "        [ 1.0966],\n",
      "        [-0.0810]])\n",
      "\tBatch = 1, Error = 0.4891952574253082\n",
      "tensor([[4.0159],\n",
      "        [1.2179]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [1.6029]])\n",
      "\tBatch = 2, Error = 0.8601019382476807\n",
      "tensor([[2.0499],\n",
      "        [4.8080],\n",
      "        [0.3951],\n",
      "        [3.1532]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [4.8596],\n",
      "        [0.3358],\n",
      "        [2.8280]])\n",
      "tensor([[3.8128],\n",
      "        [1.3159],\n",
      "        [2.3146],\n",
      "        [3.3134]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [1.6029],\n",
      "        [2.1744],\n",
      "        [3.2023]])\n",
      "tensor([[-0.1857],\n",
      "        [ 0.7684]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 1.1995]])\n",
      "tensor([[3.7088],\n",
      "        [2.2523],\n",
      "        [1.7669],\n",
      "        [1.2814]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [2.1744],\n",
      "        [1.0966],\n",
      "        [1.6029]])\n",
      "tensor([[-0.1856],\n",
      "        [ 3.0117],\n",
      "        [ 0.7279],\n",
      "        [ 3.9252]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0810],\n",
      "        [ 3.2023],\n",
      "        [ 1.1995],\n",
      "        [ 4.8596]])\n",
      "tensor([[3.2140],\n",
      "        [0.4093]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [0.3358]])\n",
      "tensor([[4.1403],\n",
      "        [3.6027],\n",
      "        [1.9898],\n",
      "        [4.6780]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [3.2023],\n",
      "        [1.0966],\n",
      "        [4.8596]])\n",
      "tensor([[0.7054],\n",
      "        [1.1550],\n",
      "        [0.2558],\n",
      "        [2.0542]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [1.6029],\n",
      "        [0.3358],\n",
      "        [2.1744]])\n",
      "tensor([[ 2.7029],\n",
      "        [-0.1709]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [-0.0810]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7511],\n",
      "        [ 1.2922],\n",
      "        [ 2.2648],\n",
      "        [-0.1666]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [ 1.6029],\n",
      "        [ 2.1744],\n",
      "        [-0.0810]])\n",
      "tensor([[1.8229],\n",
      "        [0.3365],\n",
      "        [3.8047],\n",
      "        [4.3002]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0966],\n",
      "        [0.3358],\n",
      "        [3.6039],\n",
      "        [4.8596]])\n",
      "tensor([[0.8348],\n",
      "        [3.3375]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [3.2023]])\n",
      "tensor([[ 0.8351],\n",
      "        [-0.1617],\n",
      "        [ 0.3367],\n",
      "        [ 2.3304]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.1995],\n",
      "        [-0.0810],\n",
      "        [ 0.3358],\n",
      "        [ 2.1744]])\n",
      "tensor([[3.8274],\n",
      "        [3.3295],\n",
      "        [4.3254],\n",
      "        [1.8357]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [3.2023],\n",
      "        [4.8596],\n",
      "        [1.0966]])\n",
      "tensor([[2.7721],\n",
      "        [1.3025]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [1.6029]])\n",
      "tensor([[2.3496],\n",
      "        [1.3458],\n",
      "        [3.8554],\n",
      "        [3.3535]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1744],\n",
      "        [1.6029],\n",
      "        [3.6039],\n",
      "        [3.2023]])\n",
      "tensor([[4.0723],\n",
      "        [1.7175],\n",
      "        [0.3046],\n",
      "        [0.7756]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8596],\n",
      "        [1.0966],\n",
      "        [0.3358],\n",
      "        [1.1995]])\n",
      "tensor([[ 2.9924],\n",
      "        [-0.1539]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.8280],\n",
      "        [-0.0810]])\n",
      "tensor([[ 0.3590],\n",
      "        [ 0.8738],\n",
      "        [-0.1558],\n",
      "        [ 1.9033]], grad_fn=<MmBackward>)\n",
      "tensor([[ 0.3358],\n",
      "        [ 1.1995],\n",
      "        [-0.0810],\n",
      "        [ 1.0966]])\n",
      "tensor([[3.7512],\n",
      "        [4.2407],\n",
      "        [2.2829],\n",
      "        [3.2618]], grad_fn=<MmBackward>)\n",
      "tensor([[3.6039],\n",
      "        [4.8596],\n",
      "        [2.1744],\n",
      "        [3.2023]])\n",
      "tensor([[2.9792],\n",
      "        [1.4104]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8280],\n",
      "        [1.6029]])\n",
      "tensor([[ 1.4016],\n",
      "        [ 1.9213],\n",
      "        [-0.1575],\n",
      "        [ 4.5198]], grad_fn=<MmBackward>)\n",
      "tensor([[ 1.6029],\n",
      "        [ 1.0966],\n",
      "        [-0.0810],\n",
      "        [ 4.8596]])\n",
      "tensor([[0.3616],\n",
      "        [4.0243],\n",
      "        [2.4546],\n",
      "        [0.8849]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3358],\n",
      "        [3.6039],\n",
      "        [2.1744],\n",
      "        [1.1995]])\n",
      "tensor([[3.2089],\n",
      "        [2.7262]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2023],\n",
      "        [2.8280]])\n",
      "tensor([[1.2966],\n",
      "        [3.2493],\n",
      "        [2.7611],\n",
      "        [0.3202]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6029],\n",
      "        [3.2023],\n",
      "        [2.8280],\n",
      "        [0.3358]])\n",
      "tensor([[0.8349],\n",
      "        [1.8308],\n",
      "        [2.3288],\n",
      "        [4.3208]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1995],\n",
      "        [1.0966],\n",
      "        [2.1744],\n",
      "        [4.8596]])\n",
      "tensor([[ 3.9689],\n",
      "        [-0.1608]], grad_fn=<MmBackward>)\n",
      "tensor([[ 3.6039],\n",
      "        [-0.0810]])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100  # How many times the entire training data is seen?\n",
    "l_rate = 0.01\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr = l_rate) \n",
    "\n",
    "dataset = MyDataset(x, y)\n",
    "batch_size = 4\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "training_sample_generator = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch = %s' % epoch)\n",
    "    for batch_i, samples in enumerate(training_sample_generator):\n",
    "        predictions = model(samples['feature'])\n",
    "        error = cost(predictions, samples['label'])\n",
    "        if epoch % 10 == 0:\n",
    "            print('\\tBatch = %s, Error = %s' % (batch_i, error.item()))\n",
    "        \n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model). This is because by default, gradients are\n",
    "        # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "        # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        error.backward()\n",
    "        \n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimiser.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see how well the model has learnt the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design matrix shape: torch.Size([1000, 2])\n",
      "y_for_plotting shape: torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "#from torch.autograd.variable import Variable\n",
    "\n",
    "x_for_plotting = np.linspace(0, 2*np.pi, 1000)\n",
    "design_matrix = torch.tensor(np.vstack([np.ones(x_for_plotting.shape), x_for_plotting]).T, dtype=torch.float32)\n",
    "#print('Design matrix:\\n', design_matrix)\n",
    "print('Design matrix shape:', design_matrix.shape)\n",
    "\n",
    "y_for_plotting = model.forward(design_matrix)\n",
    "print('y_for_plotting shape:', y_for_plotting.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(x,y,'o')\n",
    "plt.plot(x_for_plotting, y_for_plotting.data.numpy(), 'r-')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('2D data (#data = %d)' % N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
